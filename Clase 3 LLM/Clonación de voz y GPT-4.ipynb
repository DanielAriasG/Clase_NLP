{"cells":[{"cell_type":"markdown","metadata":{"id":"ak5iOoGhGn5J"},"source":["# ü§ñ **Usa ChatGPT con tu voz!** utilizando las APIs de OpenAI y ElevenLabs üöÄ\n","\n","Este cuaderno te ayudar√° a utilizar las APIs de OpenAI y ElevenLabs para generar texto utilizando inteligencia artificial. Sigue las instrucciones para ingresar tus claves API y seleccionar una voz. S√≥lo tendr√°s que ir ejecutando paso a paso las siguientes celdas de c√≥digo.\n"]},{"cell_type":"markdown","metadata":{"id":"giEwWFesIOT3"},"source":["## **PASO 1:** Accede y reg√≠strate a las APIs de OpenAI e ElevenLabs\n","\n","\n","> <p>‚úèÔ∏è <b>Web de OpenAI</b> <i>(Generaci√≥n de texto)</i>\n","<br>\n","<a href=\"https://platform.openai.com/account/api\">https://platform.openai.com/account/api-keys</a>\n","\n","> <p>üîä <b>Web de ElevenLabs</b> <i>(Sintetizaci√≥n de texto a voz)</i>\n","<br>\n","<a href=\"https://beta.elevenlabs.io/\">https://beta.elevenlabs.io/</a>"]},{"cell_type":"markdown","metadata":{"id":"YJzVtF1EJ7Rw"},"source":["## **PASO 2:** Configura tu acceso a la API.\n","\n","Obten las APIs key de ambas herramientas y a√±√°delas al siguiente formulario. **Luego ejecuta la celda.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1vgGNPoKz-K"},"outputs":[],"source":["!pip install -q openai\n","!pip install -q elevenlabs\n","\n","import os\n","import openai\n","import tempfile\n","import requests\n","from IPython.display import Audio, clear_output\n","from elevenlabs import generate, play, set_api_key, voices, Models\n","\n","#@title\n","openai_api_key= \"\"\n","eleven_api_key = \"\"\n","\n","# Configure GPT-4 and Text-to-speech API keys\n","openai.api_key = openai_api_key\n","set_api_key(eleven_api_key)\n","\n","voice_list = voices()"]},{"cell_type":"markdown","metadata":{"id":"QdFOTFBPCLRp"},"source":["## **PASO 3:** Selecciona la voz a utilizar.\n","\n","Ejecuta el c√≥digo de la siguiente celda y elige la voz con la que quieres interactuar. Si has procedido a clonar tu voz en la web de *ElevenLabs*, ver√°s inclu√≠da en la lista la voz que has creado."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["34037780c9c44b97949b4698f0e1fd78","1c460de44d594f819a7eeb6a18f8deef","6142148c28e145a894ab3b12f1ad0e77"]},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1690733054900,"user":{"displayName":"daniel arias","userId":"06668180682236555248"},"user_tz":300},"id":"qEsm4oHHMts5","outputId":"dfe40477-79f1-4137-d744-6d3b185045bb"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34037780c9c44b97949b4698f0e1fd78","version_major":2,"version_minor":0},"text/plain":["Dropdown(description='Selecciona una voz:', options=('premade voice: Rachel', 'premade voice: Clyde', 'premade‚Ä¶"]},"metadata":{},"output_type":"display_data"}],"source":["#@title\n","import ipywidgets as widgets\n","\n","voice_labels = [voice.category + \" voice: \" + voice.name for voice in voice_list]\n","\n","voice_id_dropdown = widgets.Dropdown(\n","    options=voice_labels,\n","    value=voice_labels[0],\n","    description=\"Selecciona una voz:\",\n",")\n","\n","display(voice_id_dropdown)"]},{"cell_type":"markdown","metadata":{"id":"eDrGe0JoDB7h"},"source":["## **PASO 4:** Configura e interact√∫a con ChatGPT\n","\n","Puedes elegir a continuaci√≥n **con qu√© versi√≥n de ChatGPT quieres hablar**. Recuerda que la versi√≥n basada en GPT-4 tiene un coste superior al modelo GPT-3.5. Consulta la tabla de precios en el siguiente link antes de utilizarlo.\n","\n","üëâ [**Tabla de precios ChatGPT**](https://openai.com/pricing)\n","\n","Tambi√©n podr√° **configurar el comportamiento del modelo ChatGPT** modificando el mensaje de sistema. Actualmente te encontrar√°s a un chatbot un poco vacil√≥n."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"elapsed":6681,"status":"error","timestamp":1690733701770,"user":{"displayName":"daniel arias","userId":"06668180682236555248"},"user_tz":300},"id":"UtHp8FwaDt-V","outputId":"7bcb6fbf-c5cd-4bca-8991-b4a520335b8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your prompt (or type 'exit' to stop): Hola como estas\n"]},{"ename":"RateLimitError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-ac1782d62991>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mcontinuous_interaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-ac1782d62991>\u001b[0m in \u001b[0;36mcontinuous_interaction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteract_with_gpt4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-ac1782d62991>\u001b[0m in \u001b[0;36minteract_with_gpt4\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Main function to interact with GPT-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minteract_with_gpt4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mresponse_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-ac1782d62991>\u001b[0m in \u001b[0;36mget_completion\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         ]\n\u001b[0;32m---> 26\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             )\n","\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."]}],"source":["#@title Configuraci√≥n de ChatGPT.\n","chatgpt_model = \"gpt-3.5-turbo\" #@param [\"gpt-3.5-turbo\", \"gpt-4\"]\n","\n","chatgpt_system = \"You are a helpful assistant on a conversation. Answer should be not too long. Be ironic and acid\" #@param {type:\"string\"}\n","\n","# Encuentra el √≠ndice de la opci√≥n seleccionada\n","selected_voice_index = voice_labels.index(voice_id_dropdown.value)\n","selected_voice_id    = voice_list[selected_voice_index].voice_id\n","\n","# Function to get GPT-4 response\n","def get_gpt4_response(prompt):\n","    response = openai.ChatCompletion.create(\n","        model=chatgpt_model,\n","        messages=[\n","            {\"role\": \"system\", \"content\": chatgpt_system},\n","            {\"role\": \"user\", \"content\": prompt}\n","        ]\n","    )\n","    return response.choices[0].message.content\n","\n","def get_completion(prompt: str, model:str=\"gpt-3.5-turbo\"):\n","    messages=[\n","            {\"role\": \"system\", \"content\": chatgpt_system},\n","            {\"role\": \"user\", \"content\": prompt}\n","        ]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0, # this is the degree of randomness of the model's output\n","    )\n","    return response.choices[0].message[\"content\"]\n","\n","# Main function to interact with GPT-4\n","def interact_with_gpt4(prompt):\n","    response_text = get_completion(prompt)\n","\n","    import requests\n","\n","    CHUNK_SIZE = 1024\n","    url = \"https://api.elevenlabs.io/v1/text-to-speech/\" + selected_voice_id\n","\n","    headers = {\n","      \"Accept\": \"audio/mpeg\",\n","      \"Content-Type\": \"application/json\",\n","      \"xi-api-key\": eleven_api_key\n","    }\n","\n","    data = {\n","      \"text\": response_text,\n","      \"model_id\" : \"eleven_multilingual_v1\",\n","      \"voice_settings\": {\n","        \"stability\": 0.4,\n","        \"similarity_boost\": 1.0\n","      }\n","    }\n","\n","    response = requests.post(url, json=data, headers=headers)\n","\n","    # Save audio data to a temporary file\n","    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as f:\n","        for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n","            if chunk:\n","                f.write(chunk)\n","        f.flush()\n","        temp_filename = f.name\n","\n","    return temp_filename\n","\n","# Function to continuously interact with GPT-4\n","def continuous_interaction():\n","    while True:\n","        clear_output(wait=True)\n","        prompt = input(\"Enter your prompt (or type 'exit' to stop): \")\n","        if prompt.lower() == 'exit':\n","            break\n","        audio_file = interact_with_gpt4(prompt)\n","        play(audio_file, notebook=True)\n","\n","# Example usage\n","continuous_interaction()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vo3lEztAjepN"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1qY-6J4UpKZ0tOmhNmh0Ci6MSiCo6xBTP","timestamp":1690401903451},{"file_id":"13LZwruIMuhZ9Zjy19_BMoxMBfuL_L9TO","timestamp":1683030596456}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1c460de44d594f819a7eeb6a18f8deef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34037780c9c44b97949b4698f0e1fd78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DropdownModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["premade voice: Rachel","premade voice: Clyde","premade voice: Domi","premade voice: Dave","premade voice: Fin","premade voice: Bella","premade voice: Antoni","premade voice: Thomas","premade voice: Charlie","premade voice: Emily","premade voice: Elli","premade voice: Callum","premade voice: Patrick","premade voice: Harry ","premade voice: Liam","premade voice: Dorothy","premade voice: Josh","premade voice: Arnold","premade voice: Charlotte","premade voice: Matilda ","premade voice: Matthew","premade voice: James","premade voice: Joseph","premade voice: Jeremy","premade voice: Michael ","premade voice: Ethan","premade voice: Gigi","premade voice: Freya","premade voice: Grace","premade voice: Daniel","premade voice: Serena","premade voice: Adam","premade voice: Nicole","premade voice: Jessie","premade voice: Ryan ","premade voice: Sam","premade voice: Glinda","premade voice: Giovanni","premade voice: Mimi ","cloned voice: Daniel1","cloned voice: Felipe"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Selecciona una voz:","description_tooltip":null,"disabled":false,"index":40,"layout":"IPY_MODEL_1c460de44d594f819a7eeb6a18f8deef","style":"IPY_MODEL_6142148c28e145a894ab3b12f1ad0e77"}},"6142148c28e145a894ab3b12f1ad0e77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
